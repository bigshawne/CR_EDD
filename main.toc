\contentsline {section}{\numberline {1}Background and Overview}{3}%
\contentsline {section}{\numberline {2}Goals}{3}%
\contentsline {section}{\numberline {3}Milestones}{4}%
\contentsline {section}{\numberline {4}Existing Solution}{4}%
\contentsline {subsection}{\numberline {4.1}Game Modification}{4}%
\contentsline {subsubsection}{\numberline {4.1.1}Pause/Resume Feature}{4}%
\contentsline {subsubsection}{\numberline {4.1.2}Passing Image through RAM}{5}%
\contentsline {subsection}{\numberline {4.2}Game Automation: Selenium API}{6}%
\contentsline {subsubsection}{\numberline {4.2.1}Setup Selenium API}{6}%
\contentsline {subsection}{\numberline {4.3}Computer Vision: CNN}{7}%
\contentsline {subsubsection}{\numberline {4.3.1}Image Preprocessing}{7}%
\contentsline {subsubsection}{\numberline {4.3.2}Structure of Our CNN}{8}%
\contentsline {subsection}{\numberline {4.4}Reinforcement Learning: Reward Functions}{9}%
\contentsline {subsubsection}{\numberline {4.4.1}Combination of CNN and Bellman Equation}{9}%
\contentsline {subsubsection}{\numberline {4.4.2}Certain Length Memory}{9}%
\contentsline {subsubsection}{\numberline {4.4.3}Observe, Explore, and Train}{10}%
\contentsline {section}{\numberline {5}Alternative Solution}{10}%
\contentsline {subsection}{\numberline {5.1}Accuracy of Object Detection of CNN}{11}%
\contentsline {subsection}{\numberline {5.2}New Action}{12}%
\contentsline {subsection}{\numberline {5.3}New Design of the Model}{13}%
\contentsline {subsubsection}{\numberline {5.3.1}Prepartion}{13}%
\contentsline {subsubsection}{\numberline {5.3.2}New Approaction 1: Deep Q-Network (DQN) with Prioritized Experience Replay (PER)}{13}%
\contentsline {paragraph}{A Rank Based Method:}{14}%
\contentsline {paragraph}{A Proportional Variant:}{14}%
\contentsline {paragraph}{Implementation}{14}%
\contentsline {subsubsection}{\numberline {5.3.3}New Approaction 2: Advantage Actor Critic (A2C)}{15}%
\contentsline {paragraph}{Implementation}{17}%
\contentsline {subsubsection}{\numberline {5.3.4}New Approaction 3: Proximal Policy Optimization (PPO)}{18}%
\contentsline {paragraph}{Implementation}{18}%
\contentsline {subsubsection}{\numberline {5.3.5}Model Selection}{19}%
\contentsline {section}{\numberline {6}Experiments and Results}{19}%
\contentsline {subsection}{\numberline {6.1}Reward Function Setting}{19}%
\contentsline {subsubsection}{\numberline {6.1.1}The control group}{20}%
\contentsline {subsubsection}{\numberline {6.1.2}First Attempt}{20}%
\contentsline {subsubsection}{\numberline {6.1.3}Second Attempt}{21}%
\contentsline {subsubsection}{\numberline {6.1.4}Third Agent}{22}%
\contentsline {subsubsection}{\numberline {6.1.5}Agent from top view}{22}%
